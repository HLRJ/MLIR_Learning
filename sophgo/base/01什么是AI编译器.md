# 什么是AI编译器

**传统编译器**

将高级语言转化为机器指令

- Source:高级语言

c++,python,java

- Target:低级语言

**AI编译器**

- Source:计算图/算子

由各种深度学习框架，如TensorFlow、PyTorch、PaddlePaddle等，构建和训练出来的网络，
也称之为计算图。而构成计算图的各个小的模块，如Convolution、ReLU、Pooling，也称之为算子。
AI编译器和传统编译器的区别是，传统编译器是为了降低编程难度，显然，我们可以通过高级语言编程，提升编程效率。
语言的转换交给编译器就行。AI编译器虽然也起到了简化搭建网络难度的作用，但是更主要的是提升网络的性能。

**将人工智能算法部署到专用的硬件设备**

深度学习模型计算量庞大，复杂的模型结构，应对复杂的情况，模型对算力的要求也在不断加大。
普通的CPU已经难以满足需求，并且在实际的场景部署中，我们要求更高的效率，在无人驾驶中，我们需要更快的识别图像，识别车周围的人群和物体。


最先想到的是GPU，GPU可以通过并行计算进行加速，各大框架也有接口，但使用GPU加速计算存在一定的限制

- 依赖CPU的调用进行工作
- 存储与处理分离式结构影响其工作效率

TPU（张量处理器）

专用于加速深层神经网络运算的定制化ASIC芯片，大幅度提高模型性能，而如果让我们搭建的模型能够在特定的TPU上运行，需要AI编译器。

简单来说，AI编译器是将不同的深度框架编程语言=> 中间表达 => 某一平台上的代码

其中中间表达包含： 
- Top 芯片无关层：图优化、量化、推理 例如将BN（Batch  Normalization）、ReLu合并到卷积算子中提升效率。
- Tpu 芯片相关层：权重重排、算子切分、地址分配、推理等


